{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbed4604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Successful!!\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from faces import load_face_dataset\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"Imports Successful!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a90f90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECT_CONF_THRESH = 0.5\n",
    "RECOG_CONF_THRESH = 0.5\n",
    "image_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/datasets/caltech_faces_full\"\n",
    "detector_main_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/face_detector\"\n",
    "recognizer_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_recognizer_exp.yml\"\n",
    "label_encoder_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_label_encoder_exp.pickle\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4721d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 23.4597 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.1346 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 1.2511 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.57      1.00      0.73         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       0.80      1.00      0.89         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       1.00      1.00      1.00         4\n",
      "            person_k       1.00      1.00      1.00         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       1.00      1.00      1.00         4\n",
      "            person_o       1.00      0.67      0.80         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      0.75      0.86         4\n",
      "            person_r       0.80      1.00      0.89         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       1.00      1.00      1.00         6\n",
      "\n",
      "            accuracy                           0.93        90\n",
      "           macro avg       0.95      0.94      0.93        90\n",
      "        weighted avg       0.95      0.93      0.93        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 44.54\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 34.91\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 48.06\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 52.01\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 51.57\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 51.92\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 47.56\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 60.13\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 49.34\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 50.46\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 55.84\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 49.77\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 47.40\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 54.06\n",
      "[INFO] prediction: person_f, actual: person_q, confidence: 45.15\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 50.48\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 39.95\n",
      "[INFO] prediction: person_r, actual: person_g, confidence: 60.68\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 48.45\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 55.18\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 48.97\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 52.45\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 49.21\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 45.81\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 50.06\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 44.65\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 51.47\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 57.81\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 44.60\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 49.93\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 56.75\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 49.48\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 52.31\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 51.87\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 49.40\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 50.71\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 46.11\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 48.13\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 59.12\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 51.63\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 51.89\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 50.50\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 46.63\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 68.83\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 57.95\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 52.73\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 46.62\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 49.40\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 61.55\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 53.62\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 42.26\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 50.76\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 50.79\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 46.41\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 56.98\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 53.65\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 50.87\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 41.51\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 41.84\n",
      "[INFO] prediction: person_a, actual: person_g, confidence: 65.43\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 49.11\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 60.97\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 46.43\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 45.86\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 56.01\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 39.74\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 63.88\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 52.06\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 51.27\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 49.05\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 48.87\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 46.99\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 66.49\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 54.54\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 54.45\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 52.18\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 73.08\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 53.31\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 55.40\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 48.92\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=8, grid_x=6, grid_y=6)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5a44263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 21.5130 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.0947 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 0.9088 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.80      1.00      0.89         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       1.00      1.00      1.00         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       0.80      1.00      0.89         4\n",
      "            person_k       0.83      1.00      0.91         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       1.00      1.00      1.00         4\n",
      "            person_o       0.80      0.67      0.73         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      1.00      1.00         4\n",
      "            person_r       1.00      1.00      1.00         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       1.00      1.00      1.00         6\n",
      "\n",
      "            accuracy                           0.94        90\n",
      "           macro avg       0.95      0.95      0.95        90\n",
      "        weighted avg       0.95      0.94      0.94        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 42.98\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 35.79\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 52.56\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 52.61\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 53.83\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 61.20\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 48.47\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 85.17\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 53.74\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 49.59\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 70.24\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 51.70\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 44.30\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 60.02\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 53.65\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 47.79\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 37.78\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 65.14\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 48.88\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 58.96\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 48.49\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 56.28\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 51.49\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 42.16\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 51.21\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 46.99\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 57.32\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 66.55\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 41.02\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 53.45\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 71.94\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 50.58\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 55.17\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 48.99\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 52.88\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 52.33\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 40.58\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 44.66\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 74.48\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 50.57\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 55.10\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 52.49\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 47.94\n",
      "[INFO] prediction: person_k, actual: person_o, confidence: 92.34\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 72.58\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 66.57\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 53.70\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 51.68\n",
      "[INFO] prediction: person_j, actual: person_g, confidence: 78.95\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 54.90\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 39.85\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 51.23\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 54.89\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 50.54\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 76.56\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 56.81\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 53.66\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 37.82\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 39.08\n",
      "[INFO] prediction: person_o, actual: person_g, confidence: 82.93\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 53.20\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 75.90\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 41.48\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 45.56\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 56.11\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 33.38\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 88.97\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 58.56\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 53.60\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 48.08\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 47.20\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 47.12\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 79.76\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 66.80\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 67.31\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 52.24\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 92.29\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 56.56\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 63.28\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 48.43\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=3, neighbors=8, grid_x=6, grid_y=6)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32e009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 35.3729 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.1898 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 1.9491 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.80      1.00      0.89         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       1.00      1.00      1.00         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       0.80      1.00      0.89         4\n",
      "            person_k       0.83      1.00      0.91         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       1.00      1.00      1.00         4\n",
      "            person_o       0.80      0.67      0.73         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      1.00      1.00         4\n",
      "            person_r       1.00      1.00      1.00         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       1.00      1.00      1.00         6\n",
      "\n",
      "            accuracy                           0.94        90\n",
      "           macro avg       0.95      0.95      0.95        90\n",
      "        weighted avg       0.95      0.94      0.94        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 34.98\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 32.61\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 46.69\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 46.39\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 45.80\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 57.46\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 41.08\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 99.26\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 45.96\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 38.93\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 68.83\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 38.37\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 39.66\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 53.34\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 54.67\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 40.16\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 30.99\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 63.06\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 39.18\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 51.77\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 37.03\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 55.49\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 42.50\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 32.50\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 40.38\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 42.48\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 51.33\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 54.19\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 34.09\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 43.74\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 83.21\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 41.07\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 44.31\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 41.63\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 45.69\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 38.70\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 33.59\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 37.40\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 75.01\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 42.06\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 48.92\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 46.19\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 36.02\n",
      "[INFO] prediction: person_k, actual: person_o, confidence: 99.90\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 70.13\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 57.04\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 47.77\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 41.02\n",
      "[INFO] prediction: person_j, actual: person_g, confidence: 77.60\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 43.38\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 35.73\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 43.24\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 52.09\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 41.96\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 81.22\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 47.34\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 46.55\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 32.21\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 33.55\n",
      "[INFO] prediction: person_o, actual: person_g, confidence: 79.65\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 44.33\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 77.13\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 33.29\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 33.07\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 44.06\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 27.38\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 93.36\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 50.97\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 41.23\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 38.07\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 36.68\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 40.21\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 81.92\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 64.48\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 70.79\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 44.36\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 94.16\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 48.58\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 61.86\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 41.07\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=5, neighbors=8, grid_x=6, grid_y=6)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c45b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 21.3899 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.0559 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 0.6668 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.80      1.00      0.89         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       1.00      1.00      1.00         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       1.00      1.00      1.00         4\n",
      "            person_k       1.00      1.00      1.00         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       1.00      1.00      1.00         4\n",
      "            person_o       0.83      0.83      0.83         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      1.00      1.00         4\n",
      "            person_r       1.00      1.00      1.00         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       0.86      1.00      0.92         6\n",
      "\n",
      "            accuracy                           0.96        90\n",
      "           macro avg       0.97      0.96      0.96        90\n",
      "        weighted avg       0.96      0.96      0.95        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 40.63\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 35.92\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 57.68\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 60.59\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 50.54\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 50.51\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 42.62\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 105.91\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 51.57\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 48.88\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 68.54\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 44.21\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 41.95\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 51.57\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 62.22\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 51.45\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 38.40\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 68.70\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 45.50\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 56.74\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 43.40\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 58.02\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 45.95\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 38.04\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 52.33\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 55.13\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 54.69\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 71.13\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 41.97\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 55.55\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 77.78\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 54.58\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 53.76\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 47.86\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 51.06\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 47.52\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 47.27\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 46.46\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 80.24\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 49.24\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 50.30\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 51.55\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 37.22\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: person_o, confidence: 105.34\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 79.65\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 64.25\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 52.80\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 50.92\n",
      "[INFO] prediction: person_o, actual: person_g, confidence: 80.48\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 47.32\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 37.47\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 49.12\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 64.28\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 47.63\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 96.63\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 51.70\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 57.15\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 40.24\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 38.63\n",
      "[INFO] prediction: person_a, actual: person_g, confidence: 79.23\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 50.68\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 75.64\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 40.98\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 43.38\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 52.62\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 27.73\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 106.25\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 54.08\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 46.78\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 45.61\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 50.98\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 43.44\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 76.31\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 73.21\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 64.38\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 47.96\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 103.53\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 48.89\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 75.11\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 49.43\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=10, neighbors=8, grid_x=6, grid_y=6)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832c01c",
   "metadata": {},
   "source": [
    "### Grid search LBP hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d515d076",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <face_LBPHFaceRecognizer 000002643620F1B0> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3c3be4e8f797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Train the classifier grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlbp_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Parameters:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0m\u001b[0;32m    428\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <face_LBPHFaceRecognizer 000002643620F1B0> was passed"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={\"radius\": [1,2,3,5,8,10,12,14,18], \n",
    "             \"neighbors\": [4,8,16,20,24,32,48],\n",
    "            \"grid_x\":[3,4,5,6,7,8],\n",
    "            \"grid_y\":[3,4,5,6,7,8]}\n",
    "\n",
    "# Make grid search classifier\n",
    "lbp_grid = GridSearchCV(cv2.face.LBPHFaceRecognizer_create(), param_grid, verbose=10)\n",
    " \n",
    "# Train the classifier grid\n",
    "lbp_grid.fit(trainX, trainY)\n",
    "\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557cdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recog",
   "language": "python",
   "name": "face_recog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
