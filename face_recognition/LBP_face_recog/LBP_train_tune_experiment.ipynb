{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b94aa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Successful!!\n",
      "Imports Successful!!\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from faces import load_face_dataset\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"Imports Successful!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933114fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECT_CONF_THRESH = 0.5\n",
    "RECOG_CONF_THRESH = 0.5\n",
    "image_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/datasets/caltech_faces_full\"\n",
    "detector_main_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/face_detector\"\n",
    "recognizer_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_recognizer.yml\"\n",
    "label_encoder_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_label_encoder.pickle\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc866c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 35.1895 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.2521 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 2.2995 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.80      1.00      0.89         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       0.80      1.00      0.89         4\n",
      "            person_g       1.00      0.80      0.89         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       1.00      1.00      1.00         4\n",
      "            person_k       1.00      1.00      1.00         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       0.80      1.00      0.89         4\n",
      "            person_o       1.00      0.83      0.91         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      0.75      0.86         4\n",
      "            person_r       1.00      1.00      1.00         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       1.00      1.00      1.00         6\n",
      "\n",
      "            accuracy                           0.96        90\n",
      "           macro avg       0.96      0.96      0.95        90\n",
      "        weighted avg       0.96      0.96      0.96        90\n",
      "\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 54.43\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 47.87\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 52.04\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 52.04\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 48.13\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 64.47\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 56.85\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 48.45\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 72.15\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 47.62\n"
     ]
    }
   ],
   "source": [
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=2, neighbors=8, grid_x=6, grid_y=6)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=10, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "    face = np.dstack([testX[i]] * 3)\n",
    "    face = imutils.resize(face, width=250)\n",
    "    # draw the predicted name and actual name on the image\n",
    "    cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    # display the predicted name, actual name, and confidence of the\n",
    "    # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "    # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "    # display the current face to our screen\n",
    "    cv2.imshow(\"detector\", face)\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e1a8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recog",
   "language": "python",
   "name": "face_recog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
