{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbed4604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Successful!!\n",
      "Imports Successful!!\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from faces import load_face_dataset\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"Imports Successful!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af262983",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECT_CONF_THRESH = 0.5\n",
    "RECOG_CONF_THRESH = 0.5\n",
    "image_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/datasets/caltech_faces_full\"\n",
    "detector_main_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/face_detector\"\n",
    "recognizer_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_recognizer_exp_r1_n8_g6.yml\"\n",
    "label_encoder_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_label_encoder_exp_r1_n8_g6.pickle\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90f90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECT_CONF_THRESH = 0.5\n",
    "RECOG_CONF_THRESH = 0.5\n",
    "image_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/datasets/caltech_faces_full\"\n",
    "detector_main_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/face_detector\"\n",
    "recognizer_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_recognizer_exp_r1_n8_g8.yml\"\n",
    "label_encoder_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_label_encoder_exp_r1_n8_g8.pickle\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4721d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 25.2640 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.1586 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 1.2676 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.57      1.00      0.73         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       0.80      1.00      0.89         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       1.00      1.00      1.00         4\n",
      "            person_k       1.00      1.00      1.00         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       1.00      1.00      1.00         4\n",
      "            person_o       1.00      0.67      0.80         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      0.75      0.86         4\n",
      "            person_r       0.80      1.00      0.89         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       1.00      1.00      1.00         6\n",
      "\n",
      "            accuracy                           0.93        90\n",
      "           macro avg       0.95      0.94      0.93        90\n",
      "        weighted avg       0.95      0.93      0.93        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 44.54\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 34.91\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 48.06\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 52.01\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 51.57\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 51.92\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 47.56\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 60.13\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 49.34\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 50.46\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 55.84\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 49.77\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 47.40\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 54.06\n",
      "[INFO] prediction: person_f, actual: person_q, confidence: 45.15\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 50.48\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 39.95\n",
      "[INFO] prediction: person_r, actual: person_g, confidence: 60.68\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 48.45\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 55.18\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 48.97\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 52.45\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 49.21\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 45.81\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 50.06\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 44.65\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 51.47\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 57.81\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 44.60\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 49.93\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 56.75\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 49.48\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 52.31\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 51.87\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 49.40\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 50.71\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 46.11\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 48.13\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 59.12\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 51.63\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 51.89\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 50.50\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 46.63\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 68.83\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 57.95\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 52.73\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 46.62\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 49.40\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 61.55\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 53.62\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 42.26\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 50.76\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 50.79\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 46.41\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 56.98\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 53.65\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 50.87\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 41.51\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 41.84\n",
      "[INFO] prediction: person_a, actual: person_g, confidence: 65.43\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 49.11\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 60.97\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 46.43\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 45.86\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 56.01\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 39.74\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 63.88\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 52.06\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 51.27\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 49.05\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 48.87\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 46.99\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 66.49\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 54.54\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 54.45\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 52.18\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 73.08\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 53.31\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 55.40\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 48.92\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# recognizer_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_recognizer_exp.yml\"\n",
    "# label_encoder_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/LBP_face_recog/output/caltech_full_label_encoder_exp.pickle\"\n",
    "\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=8, grid_x=6, grid_y=6)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5a44263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 24.0761 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.1478 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 1.5963 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.80      1.00      0.89         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       0.80      1.00      0.89         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       0.80      1.00      0.89         4\n",
      "            person_k       0.83      1.00      0.91         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       1.00      1.00      1.00         4\n",
      "            person_o       0.80      0.67      0.73         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      0.75      0.86         4\n",
      "            person_r       1.00      1.00      1.00         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       1.00      1.00      1.00         6\n",
      "\n",
      "            accuracy                           0.93        90\n",
      "           macro avg       0.94      0.94      0.93        90\n",
      "        weighted avg       0.94      0.93      0.93        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 104.50\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 83.37\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 106.93\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 121.78\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 114.05\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 122.48\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 107.90\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 134.40\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 109.38\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 113.83\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 125.35\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 111.73\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 109.53\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 118.95\n",
      "[INFO] prediction: person_f, actual: person_q, confidence: 106.50\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 113.07\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 93.56\n",
      "[INFO] prediction: person_j, actual: person_g, confidence: 134.50\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 112.75\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 121.72\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 114.01\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 119.20\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 113.70\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 103.59\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 108.83\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 103.87\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 116.54\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 126.92\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 100.36\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 114.58\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 128.05\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 112.02\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 116.83\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 115.70\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 112.41\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 112.15\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 107.63\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 107.12\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 128.15\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 116.74\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 116.60\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 112.52\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 106.11\n",
      "[INFO] prediction: person_k, actual: person_o, confidence: 153.59\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 129.62\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 118.30\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 106.46\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 113.81\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 137.50\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 118.66\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 98.57\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 116.07\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 117.03\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 110.56\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 140.11\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 121.02\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 115.27\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 96.67\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 95.94\n",
      "[INFO] prediction: person_o, actual: person_g, confidence: 146.22\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 113.69\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 136.16\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 101.77\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 103.01\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 121.53\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 91.50\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 145.87\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 116.69\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 116.03\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 112.78\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 112.45\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 106.67\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 139.51\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 122.90\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 122.71\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 116.84\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 153.74\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 118.76\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 127.90\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 111.73\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=8, grid_x=8, grid_y=8)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32e009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 32.0459 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.6298 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 26.0258 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.80      1.00      0.89         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       1.00      1.00      1.00         5\n",
      "            person_f       1.00      1.00      1.00         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       0.80      1.00      0.89         4\n",
      "            person_k       1.00      1.00      1.00         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       0.80      1.00      0.89         4\n",
      "            person_o       1.00      0.67      0.80         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      1.00      1.00         4\n",
      "            person_r       1.00      1.00      1.00         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       0.86      1.00      0.92         6\n",
      "\n",
      "            accuracy                           0.94        90\n",
      "           macro avg       0.95      0.95      0.95        90\n",
      "        weighted avg       0.95      0.94      0.94        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 145.98\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 111.75\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 147.88\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 158.92\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 160.65\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 169.94\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 149.35\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 182.50\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 158.99\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 152.19\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 173.27\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 155.56\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 140.35\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 169.75\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 141.18\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 157.38\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 124.05\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 182.63\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 155.64\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 178.79\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 156.72\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 161.58\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 158.31\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 141.65\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 153.38\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 142.90\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 170.35\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 183.52\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 140.01\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 157.23\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 178.79\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 156.57\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 166.06\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 155.22\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 156.98\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 150.82\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 135.96\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 141.98\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 178.36\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 158.33\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 156.43\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 161.69\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 145.49\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: person_o, confidence: 211.57\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 188.86\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 170.88\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 155.01\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 156.80\n",
      "[INFO] prediction: person_j, actual: person_g, confidence: 185.83\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 167.61\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 129.04\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 158.96\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 160.17\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 156.25\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 185.20\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 166.43\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 157.57\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 127.02\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 128.99\n",
      "[INFO] prediction: person_a, actual: person_g, confidence: 198.91\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 157.23\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 191.26\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 136.65\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 136.73\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 167.59\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 118.16\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 192.78\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 161.95\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 159.17\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 150.69\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 148.67\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 146.64\n",
      "[INFO] prediction: person_n, actual: person_o, confidence: 198.81\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 174.46\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 179.64\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 163.77\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 208.93\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 167.44\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 175.54\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 155.43\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=2, neighbors=12, grid_x=8, grid_y=8)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c45b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading dataset...\n",
      "21 different people's faces. \n",
      " People names: ['person_a', 'person_b', 'person_c', 'person_d', 'person_e', 'person_f', 'person_g', 'person_h', 'person_i', 'person_j', 'person_k', 'person_l', 'person_m', 'person_n', 'person_o', 'person_p', 'person_q', 'person_r', 'person_s', 'person_t', 'shubhranshu_malhotra']\n",
      "Returning black and white faces and labels\n",
      "[INFO] Detecting faces took 37.9163 seconds\n",
      "[INFO] 448 images in dataset\n",
      "[INFO] training face recognizer...\n",
      "[INFO] training took 0.6700 seconds\n",
      "[INFO] Saving the trained recognizer and label encoder.\n",
      "[INFO] gathering predictions...\n",
      "[INFO] inference on 90 images took 16.5108 seconds\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            person_a       0.80      1.00      0.89         4\n",
      "            person_b       1.00      1.00      1.00         4\n",
      "            person_c       1.00      1.00      1.00         5\n",
      "            person_d       1.00      1.00      1.00         4\n",
      "            person_e       0.83      1.00      0.91         5\n",
      "            person_f       0.80      1.00      0.89         4\n",
      "            person_g       1.00      0.60      0.75         5\n",
      "            person_i       1.00      1.00      1.00         4\n",
      "            person_j       1.00      1.00      1.00         4\n",
      "            person_k       1.00      1.00      1.00         5\n",
      "            person_l       0.83      1.00      0.91         5\n",
      "            person_m       1.00      0.75      0.86         4\n",
      "            person_n       0.80      1.00      0.89         4\n",
      "            person_o       1.00      0.67      0.80         6\n",
      "            person_p       1.00      1.00      1.00         4\n",
      "            person_q       1.00      0.75      0.86         4\n",
      "            person_r       0.80      1.00      0.89         4\n",
      "            person_s       1.00      1.00      1.00         4\n",
      "            person_t       1.00      1.00      1.00         5\n",
      "shubhranshu_malhotra       1.00      1.00      1.00         6\n",
      "\n",
      "            accuracy                           0.93        90\n",
      "           macro avg       0.94      0.94      0.93        90\n",
      "        weighted avg       0.95      0.93      0.93        90\n",
      "\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 64.05\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 51.74\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 67.43\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 71.66\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 71.56\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 71.80\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 68.12\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 76.72\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 68.11\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 69.42\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 74.59\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 68.21\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 65.26\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 72.47\n",
      "[INFO] prediction: person_f, actual: person_q, confidence: 60.97\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 70.29\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 56.29\n",
      "[INFO] prediction: person_r, actual: person_g, confidence: 79.03\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 67.86\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 74.34\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 69.39\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 72.69\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 68.81\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 64.86\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 67.32\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 65.88\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 71.38\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 76.92\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 64.45\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 67.94\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 75.32\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 68.18\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 71.44\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 71.11\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 69.95\n",
      "[INFO] prediction: person_j, actual: person_j, confidence: 69.32\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 63.90\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 67.88\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 77.03\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 71.17\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 71.34\n",
      "[INFO] prediction: person_a, actual: person_a, confidence: 69.55\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 66.85\n",
      "[INFO] prediction: person_e, actual: person_o, confidence: 88.39\n",
      "[INFO] prediction: person_i, actual: person_i, confidence: 77.86\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 72.22\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 65.83\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 68.00\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 80.63\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 72.74\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 59.07\n",
      "[INFO] prediction: person_r, actual: person_r, confidence: 69.28\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 70.99\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 67.11\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 75.22\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 72.78\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 71.47\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 61.33\n",
      "[INFO] prediction: person_m, actual: person_m, confidence: 61.24\n",
      "[INFO] prediction: person_n, actual: person_g, confidence: 83.61\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 68.02\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 80.74\n",
      "[INFO] prediction: person_q, actual: person_q, confidence: 63.60\n",
      "[INFO] prediction: person_s, actual: person_s, confidence: 65.48\n",
      "[INFO] prediction: person_l, actual: person_l, confidence: 73.96\n",
      "[INFO] prediction: person_f, actual: person_f, confidence: 56.56\n",
      "[INFO] prediction: shubhranshu_malhotra, actual: shubhranshu_malhotra, confidence: 81.37\n",
      "[INFO] prediction: person_c, actual: person_c, confidence: 72.66\n",
      "[INFO] prediction: person_e, actual: person_e, confidence: 70.62\n",
      "[INFO] prediction: person_p, actual: person_p, confidence: 66.24\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 68.10\n",
      "[INFO] prediction: person_g, actual: person_g, confidence: 65.36\n",
      "[INFO] prediction: person_a, actual: person_o, confidence: 84.48\n",
      "[INFO] prediction: person_o, actual: person_o, confidence: 72.98\n",
      "[INFO] prediction: person_n, actual: person_n, confidence: 74.79\n",
      "[INFO] prediction: person_d, actual: person_d, confidence: 71.57\n",
      "[INFO] prediction: person_l, actual: person_m, confidence: 86.79\n",
      "[INFO] prediction: person_k, actual: person_k, confidence: 72.83\n",
      "[INFO] prediction: person_b, actual: person_b, confidence: 74.62\n",
      "[INFO] prediction: person_t, actual: person_t, confidence: 69.58\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([detector_main_folder, \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([detector_main_folder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "\n",
    "# load the CALTECH faces dataset\n",
    "print(\"[INFO] loading dataset...\")\n",
    "start = time.time()\n",
    "(faces, labels) = load_face_dataset(image_folder, net, minConfidence=DETECT_CONF_THRESH, minSamples=15)\n",
    "end = time.time()\n",
    "print(\"[INFO] Detecting faces took {:.4f} seconds\".format(end - start))\n",
    "print(\"[INFO] {} images in dataset\".format(len(faces)))\n",
    "# encode the string labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "# construct our training and testing split\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# train our LBP face recognizer\n",
    "print(\"[INFO] training face recognizer...\")\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=12, grid_x=6, grid_y=6)\n",
    "start = time.time()\n",
    "recognizer.train(trainX, trainY)\n",
    "end = time.time()\n",
    "print(\"[INFO] training took {:.4f} seconds\".format(end - start))\n",
    "\n",
    "# Save trained recognizer and label encoder\n",
    "print(\"[INFO] Saving the trained recognizer and label encoder.\")\n",
    "# save the actual face recognition model to disk\n",
    "recognizer.save(recognizer_save_path)\n",
    "# write the label encoder to disk\n",
    "f = open(label_encoder_save_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n",
    "\n",
    "# initialize the list of predictions and confidence scores\n",
    "print(\"[INFO] gathering predictions...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "start = time.time()\n",
    "# loop over the test data\n",
    "for i in range(0, len(testX)):\n",
    "    # classify the face and update the list of predictions and\n",
    "    # confidence scores\n",
    "    (prediction, conf) = recognizer.predict(testX[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "# measure how long making predictions took\n",
    "end = time.time()\n",
    "print(\"[INFO] inference on {} images took {:.4f} seconds\".format(len(testX), end - start))\n",
    "# show the classification report\n",
    "print(classification_report(testY, predictions, target_names=le.classes_))\n",
    "\n",
    "# generate a sample of testing data\n",
    "idxs = np.random.choice(range(0, len(testY)), size=80, replace=False)\n",
    "\n",
    "# loop over a sample of the testing data\n",
    "for i in idxs:\n",
    "    # grab the predicted name and actual name\n",
    "#     print(predictions)\n",
    "#     print()\n",
    "    predName = le.inverse_transform([predictions[i]])[0]\n",
    "    actualName = le.classes_[testY[i]]\n",
    "    # grab the face image and resize it such that we can easily see\n",
    "    # it on our screen\n",
    "#     face = np.dstack([testX[i]] * 3)\n",
    "#     face = imutils.resize(face, width=250)\n",
    "#     # draw the predicted name and actual name on the image\n",
    "#     cv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "#     cv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
    "#         cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#     # display the predicted name, actual name, and confidence of the\n",
    "#     # prediction (i.e., chi-squared distance; the *lower* the distance\n",
    "#     # is the *more confident* the prediction is)\n",
    "    print(\"[INFO] prediction: {}, actual: {}, confidence: {:.2f}\".format(predName, actualName, confidence[i]))\n",
    "#     # display the current face to our screen\n",
    "#     cv2.imshow(\"detector\", face)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "#     elif key == ord('n'):\n",
    "#         continue\n",
    "    \n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832c01c",
   "metadata": {},
   "source": [
    "### Grid search LBP hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d515d076",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <face_LBPHFaceRecognizer 000002643620F1B0> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3c3be4e8f797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Train the classifier grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlbp_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Parameters:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\face_recog\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0m\u001b[0;32m    428\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <face_LBPHFaceRecognizer 000002643620F1B0> was passed"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={\"radius\": [1,2,3,5,8,10,12,14,18], \n",
    "             \"neighbors\": [4,8,16,20,24,32,48],\n",
    "            \"grid_x\":[3,4,5,6,7,8],\n",
    "            \"grid_y\":[3,4,5,6,7,8]}\n",
    "\n",
    "# Make grid search classifier\n",
    "lbp_grid = GridSearchCV(cv2.face.LBPHFaceRecognizer_create(), param_grid, verbose=10)\n",
    " \n",
    "# Train the classifier grid\n",
    "lbp_grid.fit(trainX, trainY)\n",
    "\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557cdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recog",
   "language": "python",
   "name": "face_recog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
