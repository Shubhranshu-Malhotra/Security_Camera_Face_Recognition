{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e69b628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.3\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import imutils\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2606fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECT_CONF_THRESH = 0.5\n",
    "RECOG_CONF_THRESH = 0.5\n",
    "detector_main_folder = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/DL_dlib_SVM/face_detection_model/\"\n",
    "encodings_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/DL_dlib_SVM/output/caltech_train_encodings.pickle\"\n",
    "recognizer_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/DL_dlib_SVM/output/caltech_train_recognizer.pickle\"\n",
    "label_encoder_save_path = \"D:/Projects/security_camera_face_recognition/Security_Camera_Face_Recognition/face_recognition/DL_dlib_SVM/output/caltech_train_label_encoder.pickle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c86391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector...\n",
      "[INFO] face detector loaded.\n",
      "[INFO] loading trained face recognizer model...\n"
     ]
    }
   ],
   "source": [
    "# Load face detector model\n",
    "print(\"[INFO] loading face detector...\")\n",
    "protoPath = os.path.join(detector_main_folder, \"deploy.prototxt\")\n",
    "modelPath = os.path.join(detector_main_folder,\"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "print(\"[INFO] face detector loaded.\")\n",
    "# load the actual face recognition model along with the label encoder\n",
    "print(\"[INFO] loading trained face recognizer model...\")\n",
    "recognizer = pickle.loads(open(recognizer_save_path, \"rb\").read())\n",
    "le = pickle.loads(open(label_encoder_save_path, \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c951706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the IP camera turned on: True\n",
      "CV_CAP_PROP_FRAME_WIDTH: '640.0'\n",
      "CV_CAP_PROP_FRAME_HEIGHT : '480.0'\n",
      "CAP_PROP_FPS : '30.0'\n",
      "CAP_PROP_POS_MSEC : '0.0'\n",
      "CAP_PROP_FRAME_COUNT  : '-1.0'\n",
      "CAP_PROP_BRIGHTNESS : '128.0'\n",
      "CAP_PROP_CONTRAST : '32.0'\n",
      "CAP_PROP_SATURATION : '64.0'\n",
      "CAP_PROP_HUE : '0.0'\n",
      "CAP_PROP_GAIN  : '4.0'\n",
      "CAP_PROP_CONVERT_RGB : '1.0'\n",
      "FPS: 0.89\n",
      "FPS: 1.21\n",
      "FPS: 1.29\n",
      "FPS: 1.40\n",
      "FPS: 1.45\n",
      "FPS: 16.56\n",
      "FPS: 17.01\n",
      "FPS: 17.10\n",
      "FPS: 16.26\n",
      "FPS: 17.11\n",
      "FPS: 19.44\n",
      "FPS: 15.56\n",
      "FPS: 16.68\n",
      "FPS: 17.82\n",
      "FPS: 16.91\n",
      "FPS: 18.69\n",
      "FPS: 14.59\n",
      "FPS: 25.12\n",
      "FPS: 25.80\n",
      "FPS: 26.95\n",
      "FPS: 7.83\n",
      "FPS: 9.51\n",
      "FPS: 10.07\n",
      "FPS: 10.37\n",
      "FPS: 26.80\n",
      "FPS: 8.60\n",
      "FPS: 6.66\n",
      "FPS: 7.65\n",
      "FPS: 27.18\n",
      "FPS: 8.71\n",
      "FPS: 8.80\n",
      "FPS: 18.48\n",
      "FPS: 17.95\n",
      "FPS: 16.99\n",
      "FPS: 14.06\n",
      "FPS: 16.73\n",
      "FPS: 18.24\n",
      "FPS: 16.65\n",
      "FPS: 15.64\n",
      "FPS: 19.05\n",
      "FPS: 25.40\n",
      "FPS: 27.71\n",
      "FPS: 7.97\n",
      "FPS: 8.60\n",
      "FPS: 13.01\n",
      "FPS: 15.39\n",
      "FPS: 8.52\n",
      "FPS: 8.74\n",
      "FPS: 24.93\n",
      "FPS: 13.24\n",
      "FPS: 11.81\n",
      "FPS: 11.96\n",
      "FPS: 16.96\n",
      "FPS: 17.11\n",
      "FPS: 9.37\n",
      "FPS: 9.55\n",
      "FPS: 10.08\n",
      "FPS: 8.75\n",
      "FPS: 23.67\n",
      "FPS: 22.57\n",
      "FPS: 20.69\n",
      "FPS: 8.92\n",
      "FPS: 9.22\n",
      "FPS: 10.11\n",
      "FPS: 16.59\n",
      "FPS: 17.01\n",
      "FPS: 17.22\n",
      "FPS: 1.38\n",
      "FPS: 1.36\n"
     ]
    }
   ],
   "source": [
    "# load the image, resize it to have a width of 600 pixels (while\n",
    "# maintaining the aspect ratio), and then grab the image dimensions\n",
    "cam = cv2.VideoCapture(0)\n",
    "print('Is the IP camera turned on: {}'.format(cam.isOpened()))\n",
    "\n",
    "print(\"CV_CAP_PROP_FRAME_WIDTH: '{}'\".format(cam.get(cv2.CAP_PROP_FRAME_WIDTH))) \n",
    "\n",
    "print(\"CV_CAP_PROP_FRAME_HEIGHT : '{}'\".format(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))) \n",
    "\n",
    "print(\"CAP_PROP_FPS : '{}'\".format(cam.get(cv2.CAP_PROP_FPS))) \n",
    "\n",
    "print(\"CAP_PROP_POS_MSEC : '{}'\".format(cam.get(cv2.CAP_PROP_POS_MSEC))) \n",
    "\n",
    "print(\"CAP_PROP_FRAME_COUNT  : '{}'\".format(cam.get(cv2.CAP_PROP_FRAME_COUNT))) \n",
    "\n",
    "print(\"CAP_PROP_BRIGHTNESS : '{}'\".format(cam.get(cv2.CAP_PROP_BRIGHTNESS))) \n",
    "\n",
    "print(\"CAP_PROP_CONTRAST : '{}'\".format(cam.get(cv2.CAP_PROP_CONTRAST))) \n",
    "\n",
    "print(\"CAP_PROP_SATURATION : '{}'\".format(cam.get(cv2.CAP_PROP_SATURATION))) \n",
    "\n",
    "print(\"CAP_PROP_HUE : '{}'\".format(cam.get(cv2.CAP_PROP_HUE))) \n",
    "\n",
    "print(\"CAP_PROP_GAIN  : '{}'\".format(cam.get(cv2.CAP_PROP_GAIN))) \n",
    "\n",
    "print(\"CAP_PROP_CONVERT_RGB : '{}'\".format(cam.get(cv2.CAP_PROP_CONVERT_RGB)))\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    _,frame=cam.read()\n",
    "    time_1 = time.time()\n",
    "    image = imutils.resize(frame, width=600)\n",
    "    (h, w) = image.shape[:2]\n",
    "    \n",
    "    # construct a blob from the image\n",
    "    imageBlob = cv2.dnn.blobFromImage(\n",
    "        cv2.resize(image, (300, 300)), 1.0, (300, 300),\n",
    "        (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "    \n",
    "    # apply OpenCV's deep learning-based face detector to localize faces in the input image\n",
    "    detector.setInput(imageBlob)\n",
    "    detections = detector.forward()\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # filter out weak detections\n",
    "        if confidence > DETECT_CONF_THRESH:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the face\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Need to convert because the face_recognition.face_encoding() doesn't use coordinate system\n",
    "            box = [(startY, endX, endY, startX)]\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Compute encoding using face_recognition library\n",
    "            encodings = np.array(face_recognition.face_encodings(rgb, box))\n",
    "\n",
    "            # perform classification to recognize the face\n",
    "            preds = recognizer.predict_proba(encodings)[0]\n",
    "            j = np.argmax(preds)\n",
    "            proba = preds[j]\n",
    "            name = le.classes_[j]\n",
    "\n",
    "            # draw the bounding box of the face along with the associated probability\n",
    "            text_1 = \"{}: {:.2f}%\".format(name, proba * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "                (0, 0, 255), 2)\n",
    "#             if( true_name == name):\n",
    "#                 color = (0, 255, 0)\n",
    "#             else:\n",
    "#                 color = (0, 0, 255)\n",
    "            cv2.putText(image, text_1, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,0), 2)\n",
    "    # show the output image\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    time_2 = time.time()\n",
    "    print(f\"FPS: {1/(time_2 - time_1):.2f}\")\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006412b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recog",
   "language": "python",
   "name": "face_recog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
